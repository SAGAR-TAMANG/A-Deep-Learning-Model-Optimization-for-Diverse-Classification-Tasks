{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa47e44a",
   "metadata": {},
   "source": [
    "### Finetuning Codebase\n",
    "\n",
    "> The code for training of the baseline model is present at main.ipynb, this file contains the finetuning process of those models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d6c25",
   "metadata": {},
   "source": [
    "#### Two Step Finetuning Process\n",
    "1. Fine-Tuning\n",
    "    - Setup: Unfreeze the top layers of the base model and train with a low learning rate.\n",
    "    - Goal: To isolate and measure the performance gain from fine-tuning alone.\n",
    "\n",
    "2. Fine-Tuning + Class Weighting\n",
    "    - Setup: Take the fine-tuned model and add class weights during training.\n",
    "    - Goal: The difference in performance between this and Exp. 2 will show the exact contribution of handling class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bd041",
   "metadata": {},
   "source": [
    "1st Step Finetuning of mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configured for fine-tuning. Trainable layers: 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,405</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m6,405\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,264,389</span> (8.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,264,389\u001b[0m (8.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,532,805</span> (5.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,532,805\u001b[0m (5.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">731,584</span> (2.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m731,584\u001b[0m (2.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting mobilenetv2_finetuned model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 299ms/step - accuracy: 0.1506 - loss: 2.2143 - val_accuracy: 0.3425 - val_loss: 1.5380\n",
      "Epoch 2/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 259ms/step - accuracy: 0.3344 - loss: 1.6808 - val_accuracy: 0.4365 - val_loss: 1.3159\n",
      "Epoch 3/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 255ms/step - accuracy: 0.4616 - loss: 1.3960 - val_accuracy: 0.4862 - val_loss: 1.1801\n",
      "Epoch 4/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 264ms/step - accuracy: 0.5605 - loss: 1.1522 - val_accuracy: 0.5801 - val_loss: 1.0911\n",
      "Epoch 5/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.6495 - loss: 0.9495 - val_accuracy: 0.6133 - val_loss: 1.0322\n",
      "Epoch 6/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 261ms/step - accuracy: 0.7088 - loss: 0.8529 - val_accuracy: 0.6519 - val_loss: 0.9837\n",
      "Epoch 7/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.7617 - loss: 0.7210 - val_accuracy: 0.6740 - val_loss: 0.9483\n",
      "Epoch 8/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.7695 - loss: 0.6736 - val_accuracy: 0.6740 - val_loss: 0.9237\n",
      "Epoch 9/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.7811 - loss: 0.6537 - val_accuracy: 0.6961 - val_loss: 0.8953\n",
      "Epoch 10/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.7958 - loss: 0.6085 - val_accuracy: 0.7072 - val_loss: 0.8710\n",
      "Epoch 11/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 258ms/step - accuracy: 0.8463 - loss: 0.4879 - val_accuracy: 0.7182 - val_loss: 0.8435\n",
      "Epoch 12/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.8169 - loss: 0.5054 - val_accuracy: 0.7238 - val_loss: 0.8167\n",
      "Epoch 13/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.8466 - loss: 0.4501 - val_accuracy: 0.7348 - val_loss: 0.7988\n",
      "Epoch 14/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.8645 - loss: 0.4070 - val_accuracy: 0.7403 - val_loss: 0.7752\n",
      "Epoch 15/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step - accuracy: 0.8501 - loss: 0.4054 - val_accuracy: 0.7459 - val_loss: 0.7590\n",
      "Epoch 16/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 260ms/step - accuracy: 0.8941 - loss: 0.3387 - val_accuracy: 0.7680 - val_loss: 0.7420\n",
      "Epoch 17/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 268ms/step - accuracy: 0.9027 - loss: 0.3225 - val_accuracy: 0.7680 - val_loss: 0.7286\n",
      "Epoch 18/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 261ms/step - accuracy: 0.9043 - loss: 0.3132 - val_accuracy: 0.7735 - val_loss: 0.7070\n",
      "Epoch 19/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.9014 - loss: 0.3121 - val_accuracy: 0.7845 - val_loss: 0.6895\n",
      "Epoch 20/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - accuracy: 0.9073 - loss: 0.3055 - val_accuracy: 0.7845 - val_loss: 0.6695\n",
      "Epoch 21/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 255ms/step - accuracy: 0.9193 - loss: 0.2576 - val_accuracy: 0.7845 - val_loss: 0.6586\n",
      "Epoch 22/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 264ms/step - accuracy: 0.9368 - loss: 0.2227 - val_accuracy: 0.7901 - val_loss: 0.6486\n",
      "Epoch 23/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 254ms/step - accuracy: 0.9437 - loss: 0.2199 - val_accuracy: 0.7901 - val_loss: 0.6347\n",
      "Epoch 24/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 255ms/step - accuracy: 0.9437 - loss: 0.2008 - val_accuracy: 0.7956 - val_loss: 0.6217\n",
      "Epoch 25/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 251ms/step - accuracy: 0.9373 - loss: 0.2252 - val_accuracy: 0.7901 - val_loss: 0.6163\n",
      "Epoch 26/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 254ms/step - accuracy: 0.9454 - loss: 0.1993 - val_accuracy: 0.8011 - val_loss: 0.6088\n",
      "Epoch 27/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 258ms/step - accuracy: 0.9485 - loss: 0.1858 - val_accuracy: 0.8011 - val_loss: 0.6000\n",
      "Epoch 28/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9623 - loss: 0.1624"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# --- 1. Configuration and Setup ---\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX')\n",
    "RESULTS_DIR = 'results'\n",
    "# IMPORTANT: New model name for this experiment\n",
    "MODEL_NAME = 'mobilenetv2_finetuned' \n",
    "\n",
    "model_results_dir = os.path.join(RESULTS_DIR, MODEL_NAME)\n",
    "os.makedirs(model_results_dir, exist_ok=True)\n",
    "\n",
    "# --- (Data loading code is the same) ---\n",
    "X_train = np.load(os.path.join(PROCESSED_DIR, 'X_train.npy'))\n",
    "y_train = np.load(os.path.join(PROCESSED_DIR, 'y_train.npy'))\n",
    "X_val = np.load(os.path.join(PROCESSED_DIR, 'X_val.npy'))\n",
    "y_val = np.load(os.path.join(PROCESSED_DIR, 'y_val.npy'))\n",
    "X_test = np.load(os.path.join(PROCESSED_DIR, 'X_test.npy'))\n",
    "y_test = np.load(os.path.join(PROCESSED_DIR, 'y_test.npy'))\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'r') as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "# --- 2. Define the Model for Fine-Tuning ---\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Start with the base model frozen, just like before\n",
    "base_model.trainable = False \n",
    "\n",
    "# Add our custom head\n",
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# We will unfreeze layers *after* compilation with the initial optimizer state\n",
    "# Let's unfreeze the top 30 layers. MobileNetV2 has 154 layers.\n",
    "fine_tune_at = len(base_model.layers) - 30 \n",
    "\n",
    "base_model.trainable = True # Unfreeze the whole base model first\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False # Then re-freeze all layers up to the fine-tuning point\n",
    "\n",
    "# Compile the model with a VERY LOW learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5), # Critical for fine-tuning\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Model configured for fine-tuning. Trainable layers: {len(model.trainable_variables)}\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# --- 3. Train the Fine-Tuned Model ---\n",
    "EPOCHS = 100 # Fine-tuning often benefits from more epochs\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"\\nStarting {MODEL_NAME} model training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- (The rest of the script for visualization and saving results is identical) ---\n",
    "# --- 4. Visualize Performance and Save Figure ---\n",
    "print(\"\\nGenerating and saving performance plots...\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle(f'{MODEL_NAME} Performance', fontsize=16)\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend(loc='lower right')\n",
    "ax2.plot(history.history['loss'], label='Train Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.savefig(os.path.join(model_results_dir, 'accuracy_loss_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "# --- 5. In-Depth Evaluation and Save Results ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"\\n--- {MODEL_NAME} In-Depth Model Evaluation ---\")\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred_classes, target_names=class_names, output_dict=True)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=class_names))\n",
    "\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(os.path.join(model_results_dir, 'classification_report.csv'))\n",
    "print(f\"Classification report saved to {os.path.join(model_results_dir, 'classification_report.csv')}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'{MODEL_NAME} Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(os.path.join(model_results_dir, 'confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# --- 6. Update Summary Results File ---\n",
    "print(\"\\nUpdating summary results file...\")\n",
    "summary_file = os.path.join(RESULTS_DIR, 'summary_results.csv')\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "summary_data = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'test_accuracy': f\"{test_accuracy:.4f}\",\n",
    "    'test_loss': f\"{test_loss:.4f}\",\n",
    "    'macro_avg_f1-score': f\"{report_dict['macro avg']['f1-score']:.4f}\",\n",
    "    'weighted_avg_f1-score': f\"{report_dict['weighted avg']['f1-score']:.4f}\"\n",
    "}\n",
    "new_results_df = pd.DataFrame([summary_data])\n",
    "\n",
    "if os.path.exists(summary_file):\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    if MODEL_NAME not in summary_df['model_name'].values:\n",
    "        summary_df = pd.concat([summary_df, new_results_df], ignore_index=True)\n",
    "    else: # If model name exists, update the row\n",
    "        summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.values\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"Updated results for {MODEL_NAME} in {summary_file}\")\n",
    "else:\n",
    "    new_results_df.to_csv(summary_file, index=False)\n",
    "    print(f\"Created new summary results file at {summary_file}\")\n",
    "\n",
    "\n",
    "# --- 7. Save the Trained Model ---\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model.save(f'models/{MODEL_NAME}.keras')\n",
    "print(f\"\\nFinetuned {MODEL_NAME} model saved to 'models/{MODEL_NAME}.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4084fde",
   "metadata": {},
   "source": [
    "2nd Step Finetuning of mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight # New import for calculating weights\n",
    "\n",
    "# --- 1. Configuration and Setup ---\n",
    "PROCESSED_DIR = os.path.join('processed_data', 'BrinjalFruitX')\n",
    "RESULTS_DIR = 'results'\n",
    "# IMPORTANT: New model name for this experiment\n",
    "MODEL_NAME = 'mobilenetv2_finetuned_weighted' \n",
    "\n",
    "model_results_dir = os.path.join(RESULTS_DIR, MODEL_NAME)\n",
    "os.makedirs(model_results_dir, exist_ok=True)\n",
    "\n",
    "# --- (Data loading code is the same) ---\n",
    "X_train = np.load(os.path.join(PROCESSED_DIR, 'X_train.npy'))\n",
    "y_train = np.load(os.path.join(PROCESSED_DIR, 'y_train.npy'))\n",
    "X_val = np.load(os.path.join(PROCESSED_DIR, 'X_val.npy'))\n",
    "y_val = np.load(os.path.join(PROCESSED_DIR, 'y_val.npy'))\n",
    "X_test = np.load(os.path.join(PROCESSED_DIR, 'X_test.npy'))\n",
    "y_test = np.load(os.path.join(PROCESSED_DIR, 'y_test.npy'))\n",
    "with open(os.path.join(PROCESSED_DIR, 'class_names.json'), 'r') as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "# --- 2. Calculate Class Weights ---\n",
    "# This is the new step to handle class imbalance\n",
    "print(\"\\nCalculating class weights...\")\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "# The function returns a NumPy array. Keras's model.fit expects a dictionary.\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights calculated:\")\n",
    "print(class_weights_dict)\n",
    "\n",
    "# --- 3. Define the Model for Fine-Tuning ---\n",
    "# This section is identical to the previous 'finetuned' experiment\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "fine_tune_at = len(base_model.layers) - 30\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5), # Use the same low learning rate\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --- 4. Train the Fine-Tuned Model with Class Weights ---\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"\\nStarting {MODEL_NAME} model training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights_dict # NEW: Pass the calculated weights here\n",
    ")\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- (The rest of the script for visualization and saving results is identical) ---\n",
    "# --- 5. Visualize Performance and Save Figure ---\n",
    "print(\"\\nGenerating and saving performance plots...\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle(f'{MODEL_NAME} Performance', fontsize=16)\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend(loc='lower right')\n",
    "ax2.plot(history.history['loss'], label='Train Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.savefig(os.path.join(model_results_dir, 'accuracy_loss_plot.png'))\n",
    "plt.show()\n",
    "\n",
    "# --- 6. In-Depth Evaluation and Save Results ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"\\n--- {MODEL_NAME} In-Depth Model Evaluation ---\")\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred_classes, target_names=class_names, output_dict=True)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=class_names))\n",
    "\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(os.path.join(model_results_dir, 'classification_report.csv'))\n",
    "print(f\"Classification report saved to {os.path.join(model_results_dir, 'classification_report.csv')}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'{MODEL_NAME} Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(os.path.join(model_results_dir, 'confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# --- 7. Update Summary Results File ---\n",
    "print(\"\\nUpdating summary results file...\")\n",
    "summary_file = os.path.join(RESULTS_DIR, 'summary_results.csv')\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "summary_data = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'test_accuracy': f\"{test_accuracy:.4f}\",\n",
    "    'test_loss': f\"{test_loss:.4f}\",\n",
    "    'macro_avg_f1-score': f\"{report_dict['macro avg']['f1-score']:.4f}\",\n",
    "    'weighted_avg_f1-score': f\"{report_dict['weighted avg']['f1-score']:.4f}\"\n",
    "}\n",
    "new_results_df = pd.DataFrame([summary_data])\n",
    "\n",
    "if os.path.exists(summary_file):\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    if MODEL_NAME not in summary_df['model_name'].values:\n",
    "        summary_df = pd.concat([summary_df, new_results_df], ignore_index=True)\n",
    "    else: # If model name exists, update the row\n",
    "        summary_df.loc[summary_df['model_name'] == MODEL_NAME] = new_results_df.values\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"Updated results for {MODEL_NAME} in {summary_file}\")\n",
    "else:\n",
    "    new_results_df.to_csv(summary_file, index=False)\n",
    "    print(f\"Created new summary results file at {summary_file}\")\n",
    "\n",
    "\n",
    "# --- 8. Save the Trained Model ---\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model.save(f'models/{MODEL_NAME}.keras')\n",
    "print(f\"\\nFinetuned {MODEL_NAME} model saved to 'models/{MODEL_NAME}.keras'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
